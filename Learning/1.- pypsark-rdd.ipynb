{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee88938b",
   "metadata": {},
   "source": [
    "## Resilient Distributed Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d713d058",
   "metadata": {},
   "source": [
    "* Resilient Distributed Datasets (RDDs) are a distributed collection of *immutable* JVM objects that allow you to perform calculations very quickly\n",
    "* As the name suggests, the dataset is distributed; it is split into chunks based on some key and distributed to executor nodes\n",
    "* RDDs keep track (log) of all the transformations applied to each chunk to speed up the computations and provide a fallback if things go wrong. This is the *data lineage*.\n",
    "\n",
    "**Internal workings of an RDD**\n",
    "\n",
    "* RDDs operate (each transformation is executed ) in parallel.\n",
    "* The transformations to the dataset are lazy. This means that any transformation is only executed when an action on a dataset is called. This helps Spark to optimize the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d54ce3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkConf, SparkContext\n",
    "sc = SparkContext(conf=SparkConf().setMaster(\"local\").setAppName(\"MyApp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "646be31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import fromstring\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc2d4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating RDDs\n",
    "# Manually\n",
    "data = sc.parallelize([(\"Amber\", 10), (\"Sophie\", 8), (\"Parkin\", 90),(\"Parkin\", 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab37fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg = data.map(lambda x:(x[0] + \"PLO\", x[1] + 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e30892cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AmberPLO', 18), ('SophiePLO', 16)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dg.take()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6250d8",
   "metadata": {},
   "source": [
    "Try with other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d92eceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from a file\n",
    "VS14MORT = sc.textFile(r\"./assets/files/VS14MORT.txt.gz\", use_unicode=True, minPartitions= 4)\n",
    "# A rule of thumb would be to break your dataset into two-four partitions for each in your cluster\n",
    "# In this case 4\n",
    "# Schema => [\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bdef0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38ca24d2",
   "metadata": {},
   "source": [
    "### Transformation\n",
    "\n",
    "* The `.map(...)` transformation: The method is applied to each element of the RDD.\n",
    "\n",
    "* The `.filter(...)` transformation: allows you to select elements from your dataset that fit specified criteria.\n",
    "\n",
    "* The `.flatMap(...)` transformation: it works similarly to `.map(...)`, but it returns a flattened result instead of a list\n",
    "\n",
    "* The `.distinct(...)` transformation: This method returns a list of distinct values in a specified column\n",
    "\n",
    "* The `.sample(...)` transformation: returns a randomized sample from the dataset.\n",
    "  * False: no replacement\n",
    "  * fraction: \n",
    "  * random_state: \n",
    "\n",
    "* The `.leftOuterJoin(...)` transformation: \n",
    "  * `join`\n",
    "  * `intersection`\n",
    "\n",
    "* The `.repartition(...)` transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a3b9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users_1 = data_users.map(lambda x:eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e52ea129",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users_2 = data_users_1.flatMap(lambda x:x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe04b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CustomerId': 1001,\n",
       "  'Address': 'Avenida Iquitos 876',\n",
       "  'Age': 37,\n",
       "  'CellPhone': 981914173},\n",
       " {'CustomerId': 1002,\n",
       "  'Address': 'Avenida San Juan de Dios 126',\n",
       "  'Age': 34,\n",
       "  'CellPhone': 969461498},\n",
       " {'CustomerId': 1003,\n",
       "  'Address': 'Avenida Santa Rosa (San Juan de Lurigancho) 1086',\n",
       "  'Age': 42,\n",
       "  'CellPhone': 998535877}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_2.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1c5081",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users_3 = (\n",
    "    data_users_2\n",
    "    .filter(lambda x:x['Age']>45)\n",
    "    .filter(lambda x:re.search(r\".*28.*\",x['Address'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fda168b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CustomerId': 1029,\n",
       "  'Address': 'Avenida Balta (Barranco) 284',\n",
       "  'Age': 49,\n",
       "  'CellPhone': 995413921},\n",
       " {'CustomerId': 1159,\n",
       "  'Address': 'Avenida 28 de Julio (Lima) 1320',\n",
       "  'Age': 46,\n",
       "  'CellPhone': 981676929}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_3.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1237d83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users_4 = data_users_3.map(lambda x:x['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04a96ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[48, 49, 46, 50, 47]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_4.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb54bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_users_sample = data_users_2.sample(False, 0.1, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb28dec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CustomerId': 1006,\n",
       "  'Address': 'Avenida Circunvalación (Lima) 633',\n",
       "  'Age': 45,\n",
       "  'CellPhone': 925527751},\n",
       " {'CustomerId': 1008,\n",
       "  'Address': 'Avenida de las Américas (Lima) 1381',\n",
       "  'Age': 49,\n",
       "  'CellPhone': 944413570}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users_sample.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b65beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sales = sc.textFile(r\"C:\\Users\\LENOVO\\Desktop\\python_course\\PySpark\\Projects\\DataSales.json\", use_unicode=True, minPartitions= 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c93681e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sales_1 = data_sales.flatMap(lambda x:eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33fc4800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample\n",
    "data_sales_1_sample = data_sales_1.sample(False, 0.01, 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7351537f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CustomerId': 1163,\n",
       "  'Date': '2019-08-27T23:28:07',\n",
       "  'PaymentMethod': {'Cash': 'Debit'},\n",
       "  'Items': [{'ProductId': 10183, 'Amount': 2.0, 'Price': 6.56},\n",
       "   {'ProductId': 10475, 'Amount': 4.0, 'Price': 5.76}]}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sales_1_sample.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0355e829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274\n",
      "C:\\Users\\LENOVO\\Desktop\\python_course\\PySpark\\Projects\\DataSales.json MapPartitionsRDD[13] at textFile at NativeMethodAccessorImpl.java:0\n"
     ]
    }
   ],
   "source": [
    "print(data)\n",
    "print(data_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe2ea1",
   "metadata": {},
   "source": [
    "* The path cannot contain special characters `[]`. Note, that this also applies to paths stored on Amazon S3 or Microsoft Azure Data Storage.\n",
    "* Multiple data formats are supported: Text, parquet, JSON, Hive tables, and data from relational databases can be read using a JDBC driver. Note that Spark can automatically work with compressed datasets like the Gzipped. \n",
    "    ``` python\n",
    "    data_from_file = sc.textFile(\"VS14MORT.txt.gz\", 4)\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e8944",
   "metadata": {},
   "source": [
    "**Schema**\n",
    "* RDDs are schema-less data structures \n",
    "* So, we can mix almost anything: a tuple, a dict, or a list and Spark will not complain.\n",
    "* The .collect() method returns all the elements of the RDD to the driver where it is serialized as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "816919e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_heterogeneous = sc.parallelize([(\"Ferrari\", \"fast\"), {\"Porsche\":10000}, [10, 80, 30]]).collect()\n",
    "data_heterogeneous[1]['Porsche']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2aee5d",
   "metadata": {},
   "source": [
    "**Reading from files**\n",
    "\n",
    "* When you read from a text file, each row from the file forms an element of an RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37761179",
   "metadata": {},
   "source": [
    "### Actions\n",
    "\n",
    "Execute the scheduled task on the datase. Once you have finished transforming your data you can execute your transformations\n",
    "\n",
    "* `.take(n)`:\n",
    "* `.takeSample(n)`:\n",
    "* `.collect()`: returns all the elements of the RDD to the driver\n",
    "* `.reduce(...)`: reduces the elements of an RDD using a specified method\n",
    "* `rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)])`\n",
    "  \n",
    "  `sorted(rdd.countByKey().items())`\n",
    "  \n",
    "  `[('a', 2), ('b', 1)]`\n",
    "* The `.saveAsTextFile(...)` : \n",
    "* The `.foreach(...)` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2b6fcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'CustomerId': 1056,\n",
       "  'Date': '2019-10-18T20:47:31',\n",
       "  'PaymentMethod': {'Cash': 'Cash'},\n",
       "  'Items': [{'ProductId': 10113, 'Amount': 2.0, 'Price': 7.48},\n",
       "   {'ProductId': 10238, 'Amount': 2.0, 'Price': 7.45},\n",
       "   {'ProductId': 10144, 'Amount': 2.0, 'Price': 13.41},\n",
       "   {'ProductId': 10092, 'Amount': 2.0, 'Price': 7.99},\n",
       "   {'ProductId': 10094, 'Amount': 5.0, 'Price': 4.43},\n",
       "   {'ProductId': 10320, 'Amount': 1.0, 'Price': 12.73},\n",
       "   {'ProductId': 10437, 'Amount': 4.0, 'Price': 3.13},\n",
       "   {'ProductId': 10404, 'Amount': 4.0, 'Price': 2.32},\n",
       "   {'ProductId': 10189, 'Amount': 3.0, 'Price': 8.22},\n",
       "   {'ProductId': 10458, 'Amount': 2.0, 'Price': 4.26},\n",
       "   {'ProductId': 10125, 'Amount': 1.0, 'Price': 0.94}]},\n",
       " {'CustomerId': 1148,\n",
       "  'Date': '2020-10-11T03:21:50',\n",
       "  'PaymentMethod': {'Cash': 'Debit'},\n",
       "  'Items': [{'ProductId': 10237, 'Amount': 1.0, 'Price': 4.97},\n",
       "   {'ProductId': 10115, 'Amount': 7.0, 'Price': 9.78},\n",
       "   {'ProductId': 10089, 'Amount': 4.0, 'Price': 3.69},\n",
       "   {'ProductId': 10015, 'Amount': 7.0, 'Price': 21.18}]}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sales_1.takeSample(False, 2, 123)\n",
    "# False -> Replacement\n",
    "# 2 -> size\n",
    "# 123 -> random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1f42f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_now = data_sales_1.filter(lambda x:x['CustomerId'] == 1056).flatMap(lambda x:x['Items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d8ef23d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_now.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9721bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32b5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea95176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import download_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb3e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('webpage.txt'):\n",
    "    \n",
    "    html_page = download_page.get_page('https://www.nytimes.com/live/2022/05/27/business/economy-news-stocks-inflation?')\n",
    "    tree = fromstring(html_page)\n",
    "    html_list = tree.xpath('//p[@class=\"live-blog-post-content css-h61jh5 evys1bk0\"]//text()')\n",
    "    html_string = '\\n'.join(html_list)\n",
    "\n",
    "    with open('webpage.txt', 'w') as writer:\n",
    "        writer.write(html_string)\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a335eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the data: <class 'pyspark.rdd.RDD'>\n"
     ]
    }
   ],
   "source": [
    "data = sc.textFile('webpage.txt')\n",
    "print(\"> \",\"Type of the data:\" ,type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d09a892a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  The percentage where the price or prices were in a line  0.14935064935064934\n"
     ]
    }
   ],
   "source": [
    "lines_prices = data.map(lambda x: len(re.findall(r'price[ s]', x, re.I)))\n",
    "print('> ', \"The percentage where the price or prices were in a line \",lines_prices.sum()/data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65c3b2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">  Here works the transformations:  <class 'pyspark.rdd.PipelinedRDD'>\n",
      ">  Here wrok the actions:  <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"> \",\"Here works the transformations: \", type(lines_prices))\n",
    "print(\"> \",\"Here work the actions: \" ,type(lines_prices.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9304ba65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47c1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfc829c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "data_4 = data_3.filter(lambda x:re.search(r'^b.*', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6d9f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4 = data_2.map(lambda x: (x, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8abade1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('name', <pyspark.resultiterable.ResultIterable at 0x176b5e96af0>),\n",
       " (' age', <pyspark.resultiterable.ResultIterable at 0x176b5e96850>),\n",
       " ('dante', <pyspark.resultiterable.ResultIterable at 0x176b5e96790>),\n",
       " (' 10', <pyspark.resultiterable.ResultIterable at 0x176b5e96700>),\n",
       " ('bryan', <pyspark.resultiterable.ResultIterable at 0x176b5e96640>),\n",
       " (' 15', <pyspark.resultiterable.ResultIterable at 0x176b5e960d0>),\n",
       " ('gregory', <pyspark.resultiterable.ResultIterable at 0x176b3bf4a90>),\n",
       " ('20', <pyspark.resultiterable.ResultIterable at 0x176b3c17ee0>)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c9249dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5 = data_4.reduceByKey(lambda x,y : str(x) + str(y)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "47d52125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bryan']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_4.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01d3f9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [2], [3], [4], [6]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize([0, 2, 3, 4, 6], 5).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef49eb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6df5f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7679c2132d3f6ce38c9df14d554b39c06862b36a4e6689c81f9ae15bd0911d7d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
